{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img, save_img\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras import datasets, layers, models, activations  \n",
    "import json\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495aa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4830e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#폴더내 파일 리스트\n",
    "file_list = os.listdir('/home/team3/hdd/Training_resized/고추')\n",
    "len(file_list)\n",
    "# file_list[10100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79250396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 데이터 확인\n",
    "plt.figure(figsize=(4,4))\n",
    "img = load_img('/home/team3/hdd/Training_resized/고추/V006_79_1_01_01_01_13_3_0149z_20201007_5_a0008.JPG')\n",
    "plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44600f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨링 데이터 확인\n",
    "ims = pd.read_json('/home/team3/hdd/Training_resized/[라벨]고추/V006_79_1_01_01_01_13_3_0149z_20201007_5_a0008.JPG.json')\n",
    "ims\n",
    "# infos = ims['description']['width']\n",
    "# infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95262c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train 이미지 폴더 내 파일 이름 목록 할당\n",
    "train_list_img=os.listdir('/home/team3/hdd/Training_resized/고추')\n",
    "len(train_list_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68064931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c26ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height=224\n",
    "image_width=224\n",
    "image_channel=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 이미지 세트를 학습한 후 다른 세트를 불러오기 위한 함수\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class Dataloader(Sequence):\n",
    "    def __init__(self, root_dir, x_set, batch_size, shuffle=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.x = x_set\n",
    "        self.y = self._get_label_data()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def _get_label_data(self):\n",
    "        y = []\n",
    "        \n",
    "        for img in self.x:\n",
    "            img_name = img.split(\"/\")[-1]\n",
    "            img_class = img.split(\"/\")[-2]\n",
    "            \n",
    "            label_name = os.path.join(self.root_dir, \"[라벨]{}\".format(img_class), img_name + \".json\")\n",
    "            img_inf = pd.read_json(label_name)\n",
    "            \n",
    "            y.append(img_inf[\"annotations\"]['disease'])\n",
    "            \n",
    "        y = np.array(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    # batch 단위로 직접 묶어줘야 함\n",
    "    def __getitem__(self, idx):\n",
    "        # sampler의 역할(index를 batch_size만큼 sampling해줌)\n",
    "        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        batch_x = []\n",
    "        for i in indices:\n",
    "            img = np.array(load_img(self.x[i]))\n",
    "            batch_x.append(img)\n",
    "\n",
    "        batch_y = [self.y[i] for i in indices]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # epoch이 끝날때마다 실행\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 경로 저장\n",
    "train_list_img = []\n",
    "valid_list_img = []\n",
    "vegt_classes = ['고추', '무', '배추', '애호박', '양배추', '오이', '콩', '토마토', '파', '호박']\n",
    "root_dir = '/home/team3/hdd/Training_resized/'\n",
    "root_dir2 = '/home/team3/hdd/Validation_resized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vegt in vegt_classes:\n",
    "    file_list = os.listdir(os.path.join(root_dir, '{}'.format(vegt)))\n",
    "    for name in file_list:\n",
    "        train_list_img.append(os.path.join(root_dir, '{}'.format(vegt), name))\n",
    "\n",
    "for vegt in vegt_classes:\n",
    "    file_list = os.listdir(os.path.join(root_dir2, '{}'.format(vegt)))\n",
    "    for name in file_list:\n",
    "        valid_list_img.append(os.path.join(root_dir2, '{}'.format(vegt), name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc280ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_img_, test_list_img_= train_test_split(train_list_img, test_size=0.2)\n",
    "train_loader = Dataloader(root_dir, train_list_img_, 128, shuffle=True)\n",
    "valid_loader = Dataloader(root_dir2, valid_list_img, 128, shuffle=True)\n",
    "test_loader = Dataloader(root_dir, test_list_img_, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab0447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 만들기\n",
    "model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None)\n",
    "\n",
    "model.add(dense)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bfb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일, 학습률 0.0001\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch이 끝날 때 loss가 적은것 가중치 기록하기\n",
    "checkpoint_path = \"checkpoint/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint_filepath = checkpoint_path\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "history = model.fit(x=train_loader,\n",
    "                    validation_data = valid_loader, \n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=10,\n",
    "                    callbacks=[model_checkpoint_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71320",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95212833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(latest)\n",
    "\n",
    "\n",
    "loss,acc = model.evaluate(test_loader, verbose=2)\n",
    "print(\"모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = os.listdir('/home/team3/hdd/Training_resized/무/')\n",
    "d = load_img('/home/team3/hdd/Training_resized/무/' + c[14000])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936275d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = img_to_array(d)\n",
    "d = d.reshape((1, 224, 224, 3))\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea441086",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = load_img('/home/team3/hdd/Training_resized/고추/V006_79_1_01_01_01_13_3_0149z_20201007_5_a0008.JPG')\n",
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbb = load_img('/home/team3/hdd/Training_resized/고추/V006_79_1_01_01_01_13_3_0149z_20201007_5_a0008.JPG')\n",
    "bbb = img_to_array(bbb)\n",
    "# bbb=np.expand_dims(bbb, axis=0)\n",
    "bbb = bbb.reshape((1, 224, 224, 3)) \n",
    "bbb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51955659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(d)\n",
    "print(pred[0][3])\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"정답은 : {np.argmax(pred, axis=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f625abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45eb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프 표현\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
